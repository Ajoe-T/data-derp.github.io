---
sidebar_position: 2
---

# Data Milky Way: Evolution
<div style={{textAlign: 'center'}}>

<figure class="video-container">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/Pf6xfgsVuSI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>

</div>

## Databases & Data Warehouses
Read: [Databases: Scale Up vs Scale Out](https://hackernoon.com/database-scaling-horizontal-and-vertical-scaling-85edd2fd9944)

<div style={{textAlign: 'center'}}>

<figure class="video-container">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/-v3PhEtOuxw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</figure>

</div>

Up until the mid-late 2000s, businesses predominantly stored both [OLTP and OLAP (above video)](https://www.youtube.com/watch?v=-v3PhEtOuxw&ab_channel=DataCamp) data in relational databases (RDBMS)
* e.g. Oracle, Microsoft SQL Server, MySQL, PostgreSQL, etc.
* OLAP-oriented databases for storing large amounts of data were called **Data Warehouses**
* Relational databases were notoriously difficult to distribute/scale out
* As more data came in, businesses often opted to **scale up** üí∞
  * Greater investment risk
  * Difficult to plan capacity
  * Expensive
  * Restrictive limits to CPU & memory
  * for a **single** server

* Data Warehouses required careful **upfront** planning:
  * Schema and layout need to be decided beforehand
  * Query patterns/use-cases needed to be preempted

<div style={{textAlign: 'center'}}>

  ![scaling.png](./assets/scaling.png)

</div>


## Hadoop Hype Train
<div style={{textAlign: 'center'}}>

![joy-of-hadoop.png](./assets/joy-of-hadoop.png)

</div>


In 2004, Google published the [MapReduce](https://www.youtube.com/watch?v=s8EPQpgpWVE&ab_channel=CBTNuggets) whitepaper, inspiring the Apache Hadoop project
* enabled **(on-prem)** distributed data processing on **commodity (cheap) hardware**
* businesses began throwing data into their Hadoop clusters!

<div style={{textAlign: 'center'}}>

![hadoop-network.png](./assets/hadoop-network.png)

Read: [What you need to know about Hadoop](https://www.oreilly.com/content/hadoop-what-you-need-to-know/)

</div>


## The Hadoop Disillusionment
<div style={{textAlign: 'center'}}>

![hadoop-has-failed-us.png](./assets/hadoop-has-failed-us.png)

</div>

Important excerpts:

:::info

Hadoop is great if you're a datascientist who knows how to code in MapReduce or Pig, Johnson says, but as you go higher up the stack, the **abstraction layers have mostly failed to deliver on the promise of enabling business analystics to get at the data.**

:::

:::info

"At the Hive layer, it's kind of OK. But people think they're going to use Hadoop for data warehouse...**are pretty surprised that this hot new technology is 10x slower than what they're using before**," Johnson says.
:::


While data locality + coupling storage and compute in Hadoop clusters was a decent idea for data throughput‚Ä¶ 
* Businesses were forced to increase **both** CPU & Disk when they often only needed to
scale up just one or the other
* You‚Äôd have to pay for more CPU just to store inactive, rarely-utilized data, what a waste!
* Storing and replicating data on HDFS (Hadoop Distributed File System) was **expensive**
and difficult to maintain
* Query performance was **lackluster** and other beneficial properties of RDBMS were gone

## Cloud Revolution
Cloud Revolution: [Why object storage wins over Hadoop-based storage](https://www.ibm.com/cloud/blog/cutting-cord-separating-data-compute-data-lake-object-storage)
* To scale cost-effectively, we need to really separate compute and storage
  * e.g. simply provision more CPU-intensive clusters only when needed, while leaving storage the same
* As analytics and AI began to involve images, audio, unstructured data:
  * Cloud Data Lakes (often based on object storage) became the ideal storage solution
  * Rapid shift away from Hadoop storage (HDFS) [[must-read](https://blogs.oracle.com/bigdata/post/what-is-object-storage)]

Time for unified analytics/query engines such as Spark and Presto to shine  üí´
* [Spark](https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ch01.html) & [Presto](https://prestodb.io/overview.html)
* 2021 newcomer: [Dremio](https://www.dremio.com/)
Both engines excel when running analytical queries against data stored on Object Storage (e.g. Amazon S3, Azure Blob Storage)
Both engines take advantage of **both memory and disk** (unlike Hadoop MapReduce which read/writes data via disk only)

Presto is very popular for **ad-hoc interactive SQL queries**
(fun fact: AWS Athena is a serverless offering based on Presto)

Spark is **extremely popular for programmatic (Python/Scala/Java/R)
use-cases** but can also support SQL queries

<div style={{textAlign: 'center'}}>

![urs-hoelzle.png](./assets/urs-hoelzle.png)

Senior Vice President of Technical Infrastructure, Google

</div>

## Unified Analytics Engines

Common Misconceptions:
* ‚ÄúSpark & Presto are NoSQL databases/data stores‚Äù
  * They‚Äôre not. But they can read/write from them üòÄ
* ‚ÄúSpark or Presto can replace all my databases‚Äù
* ‚ÄúSpark is an ‚ÄòIn-Memory‚Äô technology‚Äù
  * PostgreSQL/MySQL also cache data in RAM to speed up queries...but would you dare to call them ‚ÄòIn-Memory‚Äô technologies? üòÖ

<div style={{textAlign: 'center'}}>

![spark.png](./assets/spark.png)
![presto-cluster.png](./assets/presto-cluster.png)

</div>

Many companies (especially tech giants) can even often have both Spark and Presto/Athena in their stack

<div style={{textAlign: 'center'}}>

![presto-spark-netflix-platform.png](./assets/presto-spark-netflix-platform.png)

</div>